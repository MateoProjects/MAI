{"cells":[{"cell_type":"markdown","metadata":{"id":"EMiasIUbUU8E"},"source":["##P2: Transfer Learning and Feature Extraction"]},{"cell_type":"markdown","metadata":{"id":"_r8HbfhZT0BE"},"source":["**1) General imports and definitions**"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24691,"status":"ok","timestamp":1653321462529,"user":{"displayName":"Ramon Mateo Navarro","userId":"07442703126175469251"},"user_tz":-120},"id":"cBvjPwLRUPGb","outputId":"ef74cacd-bd02-4441-9e17-59dc1eda5956"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mon May 23 15:57:17 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   40C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","Using Keras version 2.8.0\n","Mounted at /content/gdrive\n"]}],"source":["#Check if NVIDIA GPU is enabled\n","!nvidia-smi\n","\n","# IMPORTS\n","import numpy as np\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import pandas as pd\n","from sklearn.metrics import classification_report, confusion_matrix\n","import skimage.io as sio\n","import tensorflow as tf\n","import keras\n","\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras import applications\n","from keras.models import Sequential, model_from_json, Model\n","from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout\n","from keras.utils import np_utils\n","from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","\n","print( 'Using Keras version', keras.__version__)\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","#!ln -s /content/gdrive/My\\ Drive/ /mydrive"]},{"cell_type":"markdown","metadata":{"id":"54cuYf7UT-a0"},"source":["**2) Extract images plus create training, validation and test datasets**"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Hk8AKfGTUKeK","executionInfo":{"status":"ok","timestamp":1653321483357,"user_tz":-120,"elapsed":20834,"user":{"displayName":"Ramon Mateo Navarro","userId":"07442703126175469251"}}},"outputs":[],"source":["!mkdir data\n","# \n","!cp /content/gdrive/MyDrive/DL/L2/MAMe_data_256.zip .\n","!cp /content/gdrive/MyDrive/DL/L2/MAMe_metadata.zip .\n","#!unzip /content/gdrive/MyDrive/DL/L2/MAMe_data_256.zip -d content/data\n","!unzip  -qq MAMe_data_256.zip -d data"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1143,"status":"ok","timestamp":1653321484492,"user":{"displayName":"Ramon Mateo Navarro","userId":"07442703126175469251"},"user_tz":-120},"id":"xye6PAh06sqz","outputId":"2d726cbc-9e1d-49fe-e4f0-5498e5d3c6fc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  MAMe_metadata.zip\n","  inflating: MAMe_dataset.csv        \n","  inflating: MAMe_labels.csv         \n","  inflating: MAMe_toy_dataset.csv    \n"]}],"source":["!unzip MAMe_metadata.zip\n","!cp /content/gdrive/MyDrive/DL/L2/MAMe_dataset.csv .\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"NaFUcYMHUOlP","executionInfo":{"status":"ok","timestamp":1653321484493,"user_tz":-120,"elapsed":3,"user":{"displayName":"Ramon Mateo Navarro","userId":"07442703126175469251"}}},"outputs":[],"source":["labels_list = pd.read_csv(\"/content/MAMe_dataset.csv\")\n","labels = pd.read_csv(\"/content/MAMe_labels.csv\", names=[\"id\", \"name\"])\n","\n","final_labels = labels[\"name\"].tolist()\n","labels_list[\"Medium\"] = labels_list[\"Medium\"].apply(final_labels.index)\n","\n","# Training dataset\n","train_labels_list = labels_list[labels_list[\"Subset\"] == \"train\"]\n","\n","# Validation dataset\n","val_labels_list = labels_list[labels_list[\"Subset\"] == \"val\"]\n","\n","# Test dataset\n","test_labels_list = labels_list[labels_list[\"Subset\"] == \"test\"]\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"z5HOftsuLWHp","executionInfo":{"status":"ok","timestamp":1653321484909,"user_tz":-120,"elapsed":418,"user":{"displayName":"Ramon Mateo Navarro","userId":"07442703126175469251"}}},"outputs":[],"source":["from skimage.transform import rotate\n","import random\n","labels = np.arange(29)\n","img_rows, img_cols, channels = 256, 256, 3\n","input_shape = (img_rows, img_cols, channels)\n","\n","class CustomDataGenerator(tf.keras.utils.Sequence):\n","    'Generates data for Keras'\n","    def __init__(self, set_labels_list, batch_size, shuffle=True):\n","        'Initialization'\n","        self.set_labels_list = set_labels_list\n","        self.batch_size = batch_size\n","        self.shuffle = shuffle\n","\n","        self.all_y = np.array(self.set_labels_list[\"Medium\"])\n","        self.all_y = np_utils.to_categorical(self.all_y, 29)\n","\n","    def __len__(self):\n","        'Denotes the number of batches per epoch'\n","        return int(np.floor(len(self.set_labels_list['Image file']) / self.batch_size))\n","\n","    def __getitem__(self, index):\n","        'Generate one batch of data'\n","        X = []\n","        for train_file in self.set_labels_list[\"Image file\"][index*self.batch_size:(index*self.batch_size)+self.batch_size]:\n","            im = sio.imread(\"data/data_256/\" + str(train_file))\n","            #num = random.randint(0,3)\n","            #if num % 2 == 0:\n","            #  im = rotate(im, random.randint(0,350), resize=False, center=None, order=None)\n","            #im = resize(im, (im.shape[0] // 4 , im.shape[1] // 4), anti_aliasing=True)\n","            X.append(im)  \n","        X = np.array(X) / 255.0\n","        X = X.reshape(X.shape[0], img_rows, img_cols, channels)\n","        y = self.all_y[index*self.batch_size:(index*self.batch_size)+self.batch_size]\n","        return X, y"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"JHvgRXAzLdHx","executionInfo":{"status":"ok","timestamp":1653321484910,"user_tz":-120,"elapsed":6,"user":{"displayName":"Ramon Mateo Navarro","userId":"07442703126175469251"}}},"outputs":[],"source":["# Hyperparameters\n","batch_norm = False\n","dropout = False\n","double_conv = False\n","learning_rate = 0.001\n","epochs = 100\n","batch_size = 128\n","hidden_neurons = 32"]},{"cell_type":"markdown","metadata":{"id":"7GR9WOa4WpXv"},"source":["## Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":858,"status":"ok","timestamp":1653307939466,"user":{"displayName":"Ramon Mateo Navarro","userId":"07442703126175469251"},"user_tz":-120},"id":"y0TPa2dRBZ_-","outputId":"25f9e73b-770b-4ef6-ee25-fa48d78095aa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_8\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_7 (InputLayer)        [(None, 256, 256, 3)]     0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 256, 256, 64)      1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 256, 256, 64)      36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 128, 128, 64)      0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 128, 128, 128)     73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 128, 128, 128)     147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 64, 64, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 64, 64, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 64, 64, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 64, 64, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 32, 32, 256)       0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 32, 32, 512)       1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 32, 32, 512)       2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 32, 32, 512)       2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 16, 16, 512)       0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 16, 16, 512)       2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n","                                                                 \n"," flatten_3 (Flatten)         (None, 32768)             0         \n","                                                                 \n"," dense_9 (Dense)             (None, 4096)              134225920 \n","                                                                 \n"," dense_10 (Dense)            (None, 1024)              4196352   \n","                                                                 \n"," dense_11 (Dense)            (None, 29)                29725     \n","                                                                 \n","=================================================================\n","Total params: 153,166,685\n","Trainable params: 150,251,037\n","Non-trainable params: 2,915,648\n","_________________________________________________________________\n","None\n"]}],"source":["from keras.layers.advanced_activations import PReLU\n","\n","model = applications.vgg16.VGG16(weights = \"imagenet\", include_top=False, input_shape = input_shape)\n","\n","for layer in model.layers[:12]:\n","  layer.trainable = False\n","\n","# Adding custom Layers \n","x = model.output\n","x = Flatten()(x)\n","x = Dense(4096, activation=PReLU())(x)\n","x = Dense(1024, activation=PReLU())(x)\n","predictions = Dense(29, activation=\"softmax\")(x)\n","\n","# creating the final model \n","model_final = Model(model.input, predictions)\n","print(model_final.summary())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aQ_R7JkBKWP5"},"outputs":[],"source":["train = CustomDataGenerator(train_labels_list, batch_size=batch_size, shuffle=True)\n","val = CustomDataGenerator(val_labels_list, batch_size=batch_size, shuffle=True)\n","test = CustomDataGenerator(test_labels_list, batch_size=batch_size, shuffle=True)\n","\n","datagen = ImageDataGenerator(\n","        rotation_range=0,  \n","        zoom_range = 0.0,  \n","        width_shift_range=0.1, \n","        height_shift_range=0.1,\n","        horizontal_flip=False)\n","\n","reduce_lr= ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=0.1e-6)\n","\n","\"\"\"model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n","    '/mydrive/2022/DL/P1/model',\n","    monitor=\"val_loss\",\n","    save_best_only=True,\n",")\"\"\"\n","\n","early = EarlyStopping(\n","    patience = 5,\n","    min_delta = 1e-3,\n","    restore_best_weights=True)"]},{"cell_type":"markdown","metadata":{"id":"jIrNSIdSVu5V"},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mrQ7BB5nV0fV","outputId":"051d943d-ea19-4fa0-f84e-e1c8d38dc7c2","executionInfo":{"status":"ok","timestamp":1653307774033,"user_tz":-120,"elapsed":2158355,"user":{"displayName":"Ramon Mateo Navarro","userId":"07442703126175469251"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","158/158 [==============================] - 85s 528ms/step - loss: 3.5615 - accuracy: 0.0435 - val_loss: 3.2992 - val_accuracy: 0.0455 - lr: 0.0010\n","Epoch 2/100\n","158/158 [==============================] - 83s 524ms/step - loss: 3.1873 - accuracy: 0.0909 - val_loss: 2.9219 - val_accuracy: 0.1349 - lr: 0.0010\n","Epoch 3/100\n","158/158 [==============================] - 83s 523ms/step - loss: 2.8356 - accuracy: 0.1721 - val_loss: 2.6132 - val_accuracy: 0.2791 - lr: 0.0010\n","Epoch 4/100\n","158/158 [==============================] - 83s 525ms/step - loss: 2.6137 - accuracy: 0.2197 - val_loss: 2.3038 - val_accuracy: 0.2784 - lr: 0.0010\n","Epoch 5/100\n","158/158 [==============================] - 83s 523ms/step - loss: 2.2871 - accuracy: 0.2935 - val_loss: 1.8594 - val_accuracy: 0.4134 - lr: 0.0010\n","Epoch 6/100\n","158/158 [==============================] - 83s 523ms/step - loss: 1.9549 - accuracy: 0.3788 - val_loss: 1.6411 - val_accuracy: 0.4787 - lr: 0.0010\n","Epoch 7/100\n","158/158 [==============================] - 83s 524ms/step - loss: 1.7726 - accuracy: 0.4321 - val_loss: 1.5490 - val_accuracy: 0.5121 - lr: 0.0010\n","Epoch 8/100\n","158/158 [==============================] - 83s 522ms/step - loss: 1.5791 - accuracy: 0.5070 - val_loss: 1.7226 - val_accuracy: 0.4439 - lr: 0.0010\n","Epoch 9/100\n","158/158 [==============================] - 83s 523ms/step - loss: 1.4876 - accuracy: 0.5112 - val_loss: 1.3997 - val_accuracy: 0.5526 - lr: 0.0010\n","Epoch 10/100\n","158/158 [==============================] - 83s 522ms/step - loss: 1.3749 - accuracy: 0.5609 - val_loss: 1.5401 - val_accuracy: 0.4979 - lr: 0.0010\n","Epoch 11/100\n","158/158 [==============================] - 83s 524ms/step - loss: 1.2239 - accuracy: 0.6007 - val_loss: 1.2615 - val_accuracy: 0.5824 - lr: 0.0010\n","Epoch 12/100\n","158/158 [==============================] - 83s 523ms/step - loss: 1.0601 - accuracy: 0.6459 - val_loss: 1.1856 - val_accuracy: 0.6009 - lr: 0.0010\n","Epoch 13/100\n","158/158 [==============================] - 83s 523ms/step - loss: 0.9437 - accuracy: 0.6756 - val_loss: 1.1841 - val_accuracy: 0.5938 - lr: 0.0010\n","Epoch 14/100\n","158/158 [==============================] - 83s 522ms/step - loss: 0.8424 - accuracy: 0.7158 - val_loss: 1.3000 - val_accuracy: 0.5973 - lr: 0.0010\n","Epoch 15/100\n","158/158 [==============================] - 83s 522ms/step - loss: 0.7625 - accuracy: 0.7434 - val_loss: 1.2331 - val_accuracy: 0.6080 - lr: 0.0010\n","Epoch 16/100\n","158/158 [==============================] - 83s 524ms/step - loss: 0.6416 - accuracy: 0.7830 - val_loss: 1.0748 - val_accuracy: 0.6399 - lr: 0.0010\n","Epoch 17/100\n","158/158 [==============================] - 83s 523ms/step - loss: 0.5583 - accuracy: 0.8118 - val_loss: 1.0197 - val_accuracy: 0.6697 - lr: 0.0010\n","Epoch 18/100\n","158/158 [==============================] - 83s 522ms/step - loss: 0.4252 - accuracy: 0.8566 - val_loss: 1.0704 - val_accuracy: 0.6726 - lr: 0.0010\n","Epoch 19/100\n","158/158 [==============================] - 83s 522ms/step - loss: 0.2821 - accuracy: 0.9026 - val_loss: 1.1251 - val_accuracy: 0.6726 - lr: 0.0010\n","Epoch 20/100\n","158/158 [==============================] - 83s 522ms/step - loss: 0.3026 - accuracy: 0.8955 - val_loss: 1.0751 - val_accuracy: 0.6989 - lr: 0.0010\n","Epoch 21/100\n","158/158 [==============================] - 83s 523ms/step - loss: 0.1437 - accuracy: 0.9559 - val_loss: 0.9111 - val_accuracy: 0.7401 - lr: 1.0000e-04\n","Epoch 22/100\n","158/158 [==============================] - 83s 523ms/step - loss: 0.0914 - accuracy: 0.9775 - val_loss: 0.9390 - val_accuracy: 0.7393 - lr: 1.0000e-04\n","Epoch 23/100\n","158/158 [==============================] - 83s 522ms/step - loss: 0.0793 - accuracy: 0.9792 - val_loss: 0.9577 - val_accuracy: 0.7386 - lr: 1.0000e-04\n","Epoch 24/100\n","158/158 [==============================] - 83s 522ms/step - loss: 0.0711 - accuracy: 0.9818 - val_loss: 0.9743 - val_accuracy: 0.7415 - lr: 1.0000e-04\n","Epoch 25/100\n","158/158 [==============================] - 83s 522ms/step - loss: 0.0632 - accuracy: 0.9842 - val_loss: 0.9770 - val_accuracy: 0.7408 - lr: 1.0000e-05\n","Epoch 26/100\n","158/158 [==============================] - 83s 524ms/step - loss: 0.0625 - accuracy: 0.9846 - val_loss: 0.9798 - val_accuracy: 0.7408 - lr: 1.0000e-05\n"]}],"source":["# Compile the NN\n","model_final.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate, epsilon=0.1), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Start training\n","history = model_final.fit(train, validation_data=val, epochs = epochs, callbacks=[early, reduce_lr], batch_size = 128)"]},{"cell_type":"markdown","metadata":{"id":"1VZQ9QnkReNi"},"source":["## Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45886,"status":"ok","timestamp":1653307819911,"user":{"displayName":"Ramon Mateo Navarro","userId":"07442703126175469251"},"user_tz":-120},"id":"3WcR5zigRpv5","outputId":"28cbdff4-aa50-43c1-cb5d-a03af919b7d0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Test loss: 0.9076278805732727\n","Test accuracy: 0.7453893423080444\n"]}],"source":["# Evaluate the model with validation set\n","test = CustomDataGenerator(test_labels_list, batch_size=batch_size, shuffle=True)\n","\n","score = model_final.evaluate(test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HrLAEUVrWIXC"},"outputs":[],"source":["# Store Plots\n","matplotlib.use('Agg')\n","\n","# Accuracy plot\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train','val'], loc='upper left')\n","plt.savefig('cnn_accuracy.pdf')\n","plt.close()\n","\n","# Loss plot\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train','val'], loc='upper left')\n","plt.savefig('cnn_loss.pdf')\n","plt.close()"]},{"cell_type":"markdown","metadata":{"id":"X2MmRSATWOMA"},"source":["**7) Saving model and weights**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vUCVwZDmWSOT"},"outputs":[],"source":["# Saving model and weights\n","model_json = model_final.to_json()\n","with open('model.json', 'w') as json_file:\n","        json_file.write(model_json)\n","weights_file = \"weights-MAMe_\"+str(score[1])+\".hdf5\"\n","model.save_weights(weights_file,overwrite=True)"]},{"cell_type":"markdown","metadata":{"id":"zGl3awzmxuFV"},"source":["## Feature Extraction"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"7GZyMqjKz79M","executionInfo":{"status":"ok","timestamp":1653321484910,"user_tz":-120,"elapsed":5,"user":{"displayName":"Ramon Mateo Navarro","userId":"07442703126175469251"}}},"outputs":[],"source":["def full_network_embedding(model, image_paths, batch_size, target_layer_names, input_reshape, stats=None):\n","  feature_extractor = tf.keras.Model(\n","        inputs=model.inputs,\n","        outputs=[layer.output for layer in model.layers if layer.name in target_layer_names],\n","    )\n","  get_raw_features = lambda x: [tensor.numpy() for tensor in feature_extractor(x)]\n","\n","  # Prepare output variable\n","  feature_shapes = [layer.output_shape for layer in model.layers if layer.name in target_layer_names]\n","  len_features = sum(shape[-1] for shape in feature_shapes)\n","  features = np.empty((len(image_paths), len_features))\n","\n","  # Extract features\n","  for idx in range(0, len(image_paths), batch_size):\n","      batch_images_path = image_paths[idx:idx + batch_size]\n","      img_batch = np.zeros((len(batch_images_path), *input_reshape, 3), dtype=np.float32)\n","      for i, img_path in enumerate(batch_images_path):\n","          cv_img = cv2.imread(img_path)\n","          try:\n","              cv_img_resize = cv2.resize(cv_img, input_reshape)\n","              img_batch[i] = np.asarray(cv_img_resize, dtype=np.float32)[:, :, ::-1]\n","          except:\n","              print(img_path)\n","\n","      feature_vals = get_raw_features(img_batch)\n","      features_current = np.empty((len(batch_images_path), 0))\n","      for feat in feature_vals:\n","          #If its not a conv layer, add without pooling\n","          if len(feat.shape) != 4:\n","              features_current = np.concatenate((features_current, feat), axis=1)\n","              continue\n","          #If its a conv layer, do SPATIAL AVERAGE POOLING\n","          pooled_vals = np.mean(np.mean(feat, axis=2), axis=1)\n","          features_current = np.concatenate((features_current, pooled_vals), axis=1)\n","      # Store in position\n","      features[idx:idx+len(batch_images_path)] = features_current.copy()\n","\n","  # STANDARDIZATION STEP\n","  # Compute statistics if needed\n","  if stats is None:\n","      stats = np.zeros((2, len_features))\n","      stats[0, :] = np.mean(features, axis=0)\n","      stats[1, :] = np.std(features, axis=0)\n","  # Apply statistics, avoiding nans after division by zero\n","  features = np.divide(features - stats[0], stats[1], out=np.zeros_like(features), where=stats[1] != 0)\n","  if len(np.argwhere(np.isnan(features))) != 0:\n","      raise Exception('There are nan values after standardization!')\n","  # DISCRETIZATION STEP\n","  th_pos = 0.15\n","  th_neg = -0.25\n","  features[features > th_pos] = 1\n","  features[features < th_neg] = -1\n","  features[[(features >= th_neg) & (features <= th_pos)][0]] = 0\n","\n","  # # Store output\n","  import os\n","  outputs_path = '.'\n","  if not os.path.exists(outputs_path):\n","    os.makedirs(outputs_path)\n","  np.save(os.path.join(outputs_path, 'fne.npy'), features)\n","  np.save(os.path.join(outputs_path, 'stats.npy'), stats)\n","\n","  # Return\n","  return features, stats"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"oRGiuCzCxten","executionInfo":{"status":"ok","timestamp":1653321493492,"user_tz":-120,"elapsed":8587,"user":{"displayName":"Ramon Mateo Navarro","userId":"07442703126175469251"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"906346aa-ca3e-4778-f291-7a870e48db2f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n","553467904/553467096 [==============================] - 3s 0us/step\n","553476096/553467096 [==============================] - 3s 0us/step\n"]}],"source":["initial_model = applications.vgg16.VGG16(weights=\"imagenet\", include_top=True,\n","                                                input_shape=(224, 224, 3))\n","target_layer_names = ['block1_conv1', 'block1_conv2', 'block2_conv1', 'block2_conv2', 'block3_conv1', 'block3_conv2',\n","                          'block3_conv3', 'block4_conv1', 'block4_conv2', 'block4_conv3', 'block5_conv1', 'block5_conv2',\n","                          'block5_conv3']\n","\n","y_train = np.array(train_labels_list[\"Medium\"])\n","y_train = np_utils.to_categorical(y_train, 29)\n","y_test = np.array(test_labels_list[\"Medium\"])\n","y_test = np_utils.to_categorical(y_train, 29)\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":382,"status":"ok","timestamp":1653321493866,"user":{"displayName":"Ramon Mateo Navarro","userId":"07442703126175469251"},"user_tz":-120},"id":"lG08i0ltzAw7","outputId":"fd3e2117-938b-4b06-c366-3e266536eccb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total train images: 20300  with their corresponding 20300 labels\n","Total train images: 20300  with their corresponding 20300 labels\n"]}],"source":["## getting images\n","import cv2\n","train_images, test_images = [], []\n","for image in train_labels_list['Image file']:\n","  train_images.append('/content/data/data_256/'+ image)\n","print('Total train images:', len(train_images), ' with their corresponding', len(y_train), 'labels')\n","\n","for image in test_labels_list['Image file']:\n","  test_images.append('/content/data/data_256/'+ image)\n","print('Total train images:', len(train_images), ' with their corresponding', len(y_test), 'labels')\n"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"_cr0PLNjz6os","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653324829161,"user_tz":-120,"elapsed":801962,"user":{"displayName":"Ramon Mateo Navarro","userId":"07442703126175469251"}},"outputId":"8867c413-04f0-4010-b46a-dc6f80189136"},"outputs":[{"output_type":"stream","name":"stdout","text":["(20300, 4224) \n"," [[21.59794746 62.87631663 69.53910667 ...  0.3470342   0.32718058\n","   0.48778457]\n"," [10.2440627  28.74682553 21.05250792 ...  0.92889994  0.74857569\n","   1.45328083]]\n"]}],"source":["fne_features, fne_stats_train = full_network_embedding(initial_model, train_images, 16 ,target_layer_names, (224,224))\n","print(fne_features.shape, \"\\n\", fne_stats_train)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hvb3NAww0bg4","outputId":"a5755e63-43ef-40c0-8ac0-c40355c8d245","executionInfo":{"status":"ok","timestamp":1653325917894,"user_tz":-120,"elapsed":1088735,"user":{"displayName":"Ramon Mateo Navarro","userId":"07442703126175469251"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"output_type":"stream","name":"stdout","text":["Done training SVM on extracted features of training set\n","Done extracting features of test set\n","Done testing SVM on extracted features of test set\n"]}],"source":["from sklearn import svm\n","\"\"\"\n","# Train SVM with the obtained features.\n","clf = svm.LinearSVC()\n","clf.fit(X=fne_features, y=train_labels_list[\"Medium\"])\n","print('Done training SVM on extracted features of training set')\n","\n","# Test SVM with the test set.\n","predicted_labels = clf.predict(fne_features)\n","print('Done testing SVM on extracted features of test set')\n","\"\"\"\n","# Train SVM with the obtained features.\n","clf = svm.LinearSVC()\n","clf.fit(X=fne_features, y=train_labels_list[\"Medium\"])\n","print('Done training SVM on extracted features of training set')\n","del fne_features\n","\n","# Call FNE method on the test set, using stats from training\n","fne_features, fne_stats_train = full_network_embedding(initial_model, test_images, 16 ,\n","                                                        target_layer_names, (224,224), stats=fne_stats_train)\n","print('Done extracting features of test set')\n","\n","# Test SVM with the test set.\n","predicted_labels = clf.predict(fne_features)\n","print('Done testing SVM on extracted features of test set')\n","del fne_features"]},{"cell_type":"markdown","metadata":{"id":"w6WlmOAH0gOb"},"source":["### Classification report FE"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"KT5hm6cu0cd2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653325917895,"user_tz":-120,"elapsed":13,"user":{"displayName":"Ramon Mateo Navarro","userId":"07442703126175469251"}},"outputId":"a3b32332-371f-480e-d820-042339646e34"},"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.95      0.97      0.96       700\n","           1       0.73      0.67      0.70       700\n","           2       0.77      0.74      0.75       700\n","           3       0.78      0.83      0.81       313\n","           4       0.71      0.73      0.72       700\n","           5       0.73      0.66      0.70       700\n","           6       0.83      0.81      0.82       700\n","           7       0.79      0.72      0.76       700\n","           8       0.83      0.86      0.85       700\n","           9       0.69      0.93      0.79       188\n","          10       0.93      0.99      0.96       328\n","          11       0.93      0.96      0.95       584\n","          12       0.63      0.80      0.71       265\n","          13       0.68      0.64      0.66       572\n","          14       0.75      0.69      0.72       700\n","          15       0.83      0.71      0.76       700\n","          16       0.52      0.73      0.61       257\n","          17       0.81      0.71      0.76       700\n","          18       0.77      0.88      0.82       286\n","          19       0.47      0.62      0.54       375\n","          20       0.87      0.87      0.87       700\n","          21       0.25      0.62      0.36        95\n","          22       0.76      0.74      0.75       700\n","          23       0.66      0.91      0.76       133\n","          24       0.74      0.67      0.71       700\n","          25       0.65      0.81      0.72       361\n","          26       0.93      0.90      0.92       700\n","          27       0.89      0.87      0.88       700\n","          28       0.84      0.65      0.73       700\n","\n","    accuracy                           0.77     15657\n","   macro avg       0.75      0.78      0.76     15657\n","weighted avg       0.79      0.77      0.78     15657\n","\n","-------------------------------------------------------------------\n","[[679   1   0   0   0   1   0   0   0   3   0   0   0   1   1   0   0   5\n","    4   1   0   0   0   0   0   2   1   0   1]\n"," [  0 468  21   4   3   0  20  21   5   1   1   1  39   3   6   0   7   2\n","    1   8   2   2  53  10  18   1   0   1   2]\n"," [  0  21 516   5   2   0   9  11   7   1   3   1   1   9  28   0  27   2\n","    1  10  14   1   8   4  11   0   3   0   5]\n"," [  0   4   8 261   0   1   4   4   0   0   0   0   1  10   4   0   4   0\n","    0   1   1   1   0   0   8   0   0   0   1]\n"," [  2   0   2   2 509  83   0   0   1   6   2   1   1   2   2  14   1   0\n","    7   1   1   0   2   0   0  25   1  34   1]\n"," [  5   0   0   0  98 465   0   0   0  13   6   4   2   1   3  28   2   1\n","   15   2   0   0   0   0   1  37   4  12   1]\n"," [  0  12  11   6   1   0 566  19  11   1   0   0   3   9  10   1   7   1\n","    0   1  24   1  10   0   5   0   0   0   1]\n"," [  0  17  13   6   3   0  26 506  19   7   0   2   5  13   3   2   3   1\n","    1   2  15   3  27   6   7   2   1   0  10]\n"," [  1   8   3   3   0   0   6  10 602   0   0   0   2  19   2   0   2   1\n","    0   6   5   2  16   1   5   2   1   1   2]\n"," [  0   0   0   0   1   2   0   0   0 174   0   0   0   0   0   1   0   0\n","    8   0   0   0   0   0   0   1   0   1   0]\n"," [  0   0   0   0   1   0   0   0   0   0 324   2   0   0   0   1   0   0\n","    0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   3   1   1   0   0   0   5 561   0   0   0   5   0   0\n","    2   0   1   0   1   0   1   1   2   0   0]\n"," [  0  12   5   1   0   1   0   1   3   0   0   0 212   2   1   1   1   0\n","    1   1   0   0   1   8  12   1   0   0   1]\n"," [  2  13   8   9   1   0   8  15  22   1   0   0   1 367  19   3  16   2\n","    7   9  11   7   9   7  28   3   0   2   2]\n"," [  2  10  21   8   2   2  11   4   3   2   0   0   3  22 480   2  72   3\n","    2   8   1   7   8   4  17   1   0   2   3]\n"," [  6   3   0   0  18  33   2   2   2  16   3  18   3   1   7 497   1   1\n","    8   3   0   0   1   2   2  50  14   4   3]\n"," [  1   1   5   4   2   0   1   2   0   0   0   0   2   6  32   2 187   0\n","    0   1   3   0   2   0   4   1   0   0   1]\n"," [  4   0   0   2   2   0   1   2   2   0   0   1   1   3   2   7   1 498\n","    1 154   0   5   1   0   5   2   3   0   3]\n"," [  2   0   0   1   5   6   0   0   0  13   1   0   0   0   0   1   0   0\n","  251   0   0   1   0   0   1   0   2   1   1]\n"," [  1   4   3   7   1   0   3   0   2   1   1   1   1   3   3   2   3  85\n","    0 232   2   0   1   0  16   0   1   1   1]\n"," [  0   8   6   1   1   0  12  16   4   0   0   0   1  11   1   0  11   1\n","    0   3 608   0  12   0   0   0   0   0   4]\n"," [  0   1   0   0   0   0   0   0   2   1   0   2   0   2   0   1   0   0\n","    1   2   1  59   0   0   0   0   0   0  23]\n"," [  1  36   6   4   5   2   5  19  17   1   1   0  26  11   6   0   1   1\n","    1   5   6   1 519   8  15   0   0   0   3]\n"," [  0   1   0   0   0   0   0   0   0   0   0   0   5   2   0   0   0   0\n","    0   1   0   0   1 121   2   0   0   0   0]\n"," [  2  17  31   5   4   4   3   5  10   4   0   0  21  35  16   2  10   4\n","    1  15   3   4  12   9 472   2   0   2   7]\n"," [  2   2   0   0  18  17   0   0   1   1   0   1   1   0   1  17   0   0\n","    2   0   0   0   0   1   0 291   0   5   1]\n"," [  3   0   2   0   3   6   0   1   3   0   0   1   0   1   0   7   0   5\n","    6   8   0   2   0   0   1   4 633   7   7]\n"," [  1   0   1   0  31   8   0   0   1   2   0   4   1   0   0   4   0   1\n","    2   4   0   4   0   0   0  19   8 608   1]\n"," [  0   2   7   4   2   2   3   2   5   4   1   1   4   6  10   2   4   3\n","    6  13   4 136   2   3   6   2   8   2 456]]\n"]}],"source":["from sklearn.metrics import classification_report, confusion_matrix\n","print(classification_report(test_labels_list[\"Medium\"], predicted_labels))\n","print(\"-------------------------------------------------------------------\")\n","print(confusion_matrix(test_labels_list[\"Medium\"], predicted_labels))"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"P2.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}