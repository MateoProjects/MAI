{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DL_l2.ipynb","provenance":[],"collapsed_sections":["ZkZF505u27ps"],"machine_shape":"hm","authorship_tag":"ABX9TyOLbkgLIurgL6JsrbWXYzpU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Deep Learning Lab 2"],"metadata":{"id":"hd5uSXj_KnXq"}},{"cell_type":"markdown","source":["## Imports"],"metadata":{"id":"4zrNwjMxK5ld"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive/\")\n","\n","!cp /content/drive/MyDrive/DL/L2/MAMe_data_256.zip .\n","!cp /content/drive/MyDrive/DL/L2/MAMe_metadata.zip .\n"],"metadata":{"id":"qG3pxlwkKm1l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652519901857,"user_tz":-120,"elapsed":9376,"user":{"displayName":"Ramon Mateo Navarro","userId":"07442703126175469251"}},"outputId":"ce928232-e19b-4a89-f976-179b27ad5e54"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!unzip -qq MAMe_data_256.zip\n","!unzip -qq MAMe_metadata.zip\n","!rm MAMe_data_256.zip\n","!rm MAMe_metadata.zip\n","!rm MAMe_dataset.csv\n","!cp /content/drive/MyDrive/DL/L2/MAMe_dataset.csv .\n"],"metadata":{"id":"vIKtYas6MSFy","executionInfo":{"status":"ok","timestamp":1652523599268,"user_tz":-120,"elapsed":821781,"user":{"displayName":"Ramon Mateo Navarro","userId":"07442703126175469251"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c96a08c3-856f-451c-bbb2-9086fd858a97"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["replace data_256/100019.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: yes\n","replace data_256/100033.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n","replace MAMe_dataset.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7rP445Q3J36L"},"outputs":[],"source":["import numpy as np \n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import pandas as pd\n","import os\n","import random\n","import cv2\n","from PIL import Image\n","from skimage import io\n","from tensorflow.keras import utils\n","from tensorflow.keras.utils import Sequence\n","from tensorflow import keras\n","from keras.callbacks import EarlyStopping\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras import applications\n","from skimage.transform import rotate, rescale\n","from keras.models import Sequential, Model \n","from sklearn.preprocessing import LabelEncoder\n"]},{"cell_type":"markdown","source":["## Constants"],"metadata":{"id":"aifntWAPLmUH"}},{"cell_type":"code","source":["FILE_TEST = \"MAMe_toy_dataset.csv\"\n","FILE_TRAIN = \"MAMe_dataset.csv\"\n","NUM_CLASSES = 29\n"],"metadata":{"id":"SjGJJIiwLn2n"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Pre process"],"metadata":{"id":"DN361FnoKx6S"}},{"cell_type":"code","source":["def split_data(train, test, validation ):\n","    names_images_train = train[:,0]\n","    names_images_test = test[:,0]\n","    names_images_val = validation[:,0]\n","    y_train = train[:,1]\n","    y_test = test[:,1]\n","    y_val = validation[:,1]\n","    return (names_images_train, names_images_test, names_images_val, y_train, y_test, y_val)\n","\n","def transform_labels(labels_dict, data):\n","    \"\"\"\n","    Transform data strings to numerical labels\n","    @param labels_dict: dictionary with the labels\n","    @param data: the data to transform\n","    @return: the transformed data\n","    \"\"\"\n","    y_train, y_test, y_val = [], [], []\n","    for x in data[3]:\n","        y = np.zeros(NUM_CLASSES)\n","        y[labels_dict[x]] = 1\n","        y_train.append(y)\n","    for x in data[4]:\n","        y = np.zeros(NUM_CLASSES)\n","        y[labels_dict[x]] = 1\n","        y_test.append(y)\n","    for x in data[5]:\n","        y = np.zeros(NUM_CLASSES)\n","        y[labels_dict[x]] = 1\n","        y_val.append(y)\n","    return (np.array(y_train), np.array(y_test), np.array(y_val))\n","\n","def load_data(file):\n","    \"\"\"\n","    Split data from csv file in three parts: train, test and validation\n","    \"\"\"\n","    file_labels = pd.read_csv(file).to_numpy()\n","    train = file_labels[file_labels[:, 4] == \"train\"]\n","    test = file_labels[file_labels[:,4] == \"test\"]\n","    validation = file_labels[file_labels[:,4] == \"val\"]\n","    return split_data(train, test, validation)\n","    #print(\"Train size: \", len(train), \"\\nTest size: \", len(test), \"\\nValidation size: \", len(validation))\n","\n","def labels_to_dict(labels):\n","    my_labels = {}\n","    for i in range(len(labels)):\n","        my_labels[labels[i,1]] = labels[i,0]\n","    return my_labels\n","\n","\n","def load_labels():\n","    \"\"\"\n","    Load labels from csv file\n","    @return numpy array of labels\n","    \"\"\"\n","    labels = pd.read_csv(\"MAMe_labels.csv\", header=None).to_numpy()\n","    return labels_to_dict(labels)\n","    \n","def load_images(data):\n","    \"\"\"\n","    Load images from name of given in the data\n","    @param data: numpy array with names of images\n","    @return numpy array with images\n","    \"\"\"\n","    data_x = []\n","    for name in data:\n","        img = io.imread(\"data_256/\" + name)\n","        data_x.append(img)\n"," \n","    return np.array(data_x)\n","\n"],"metadata":{"id":"SRlPlN5FKz63"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_valSet(x_test, y_test, rotation=0, horizontal_flip=False):\n","    \"\"\"\n","    Gets the validation set.\n","    :param x_test: test set\n","    :param y_test: test labels\n","    :return: validation set\n","    \"\"\"\n","    val_data_gen_args = dict(rescale = None,\n","                      samplewise_center=True,\n","                      samplewise_std_normalization=True,\n","                      rotation_range=rotation,\n","                      horizontal_flip=horizontal_flip)\n","   \n","    val_datagen = ImageDataGenerator(val_data_gen_args)\n","    val_set = val_datagen.flow(x_test, y_test, batch_size=BATCH_SIZE)\n","    return val_set\n"],"metadata":{"id":"tm7znqQSwj2t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data Augmentation"],"metadata":{"id":"T1N5reJIzFcb"}},{"cell_type":"code","source":["def data_augmentation(x_names, y_names, val):\n","  x = []\n","  y = []\n","  print(x_names.shape, y_names.shape)\n","  #seed = random.randint(0,50)\n","  #random.Random(seed).shuffle(x_names)\n","  #random.Random(seed).shuffle(y_names)\n","  for i in range(int(len(x_names)*val)):\n","    y.append(y_names[i])\n","    image = Image.open('/content/data_256/'+ x_names[i])\n","    image = image.rotate(random.randint(0, 359))\n","    name_dest = x_names[i].split('.')[0] + \"_rotated.jpg\"\n","    image.save('/content/data_256/' + name_dest)\n","    x.append(name_dest)\n","  x_train = np.concatenate((x_names, x))\n","  y_train = np.concatenate((y_names, y))\n","  return x_train, y_train"],"metadata":{"id":"B06Zf6BHzIU8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data Generator"],"metadata":{"id":"ZkZF505u27ps"}},{"cell_type":"code","source":["class DataGenerator(Sequence):\n","\n","  def __init__(self, x_names, y_names, batch_size):\n","    \n","    self.x_values = x_names.copy()\n","    self.y_values =   y_names.copy()\n","    self.num_imgs = len(x_names)\n","    self.batch_size = batch_size\n","\n","  def __getitem__(self, index):\n","\n","    # position of the batch in the sequence\n","\n","    aux_index = index * self.batch_size\n","\n","    x = [] # numpy array with shape (batch_size, input_height, input_width, input_channel)\n","    y = [] # numpy array with shape (batch_size, num_classes)\n","    \n","\n","    for _ in range(self.batch_size):\n","\n","      img_name = self.x_values[aux_index]\n","      img = cv2.imread('/content/data_256/' + img_name)\n","      x.append(img)\n","      y.append(self.y_values[aux_index])\n","      aux_index += 1\n","\n","    x = np.array(x)\n","    y = np.array(y)\n","    return x, y\n","\n","  def on_epoch_end(self):\n","    num = random.randint(0,1000)\n","    random.Random(num).shuffle(self.x_values)\n","    random.Random(num).shuffle(self.y_values)\n","\n","  def __len__ (self):\n","    # return the number of batches the generator can produce\n","    return (self.num_imgs) // self.batch_size"],"metadata":{"id":"G1UbIM9s27Ar"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_valSet(x_test, y_test, rotation=False):\n","    \"\"\"\n","    Gets the validation set.\n","    :param x_test: test set\n","    :param y_test: test labels\n","    :return: validation set\n","    \"\"\"\n","    val_data_gen_args = dict(rescale = None,\n","                     samplewise_center=True,\n","                     samplewise_std_normalization=True)\n","   \n","    val_datagen = ImageDataGenerator(val_data_gen_args)\n","    val_set = val_datagen.flow(x_test, y_test, batch_size=BATCH_SIZE)\n","    return val_set"],"metadata":{"id":"r3hXo4hHA1DQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Feature Extraction"],"metadata":{"id":"-qBRlkHnCg9L"}},{"cell_type":"markdown","source":["## Fine Tunning"],"metadata":{"id":"Y4bum4-8Cj9B"}},{"cell_type":"code","source":["def train_model_fine(data_x, data_val, data_y ,lr= 0.001):\n","  img_width, img_height = 256, 256\n","  model = applications.vgg16.VGG16(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n","  #model.trainable = True\n","  for layer in model.layers[:10]:\n","    layer.trainable = False\n","\n","  #Adding custom Layers \n","  x = model.output\n","  x = keras.layers.Flatten()(x)\n","  x = keras.layers.Dense(4096, activation=\"relu\")(x)\n","  x = keras.layers.Dropout(0.2)(x)\n","  x = keras.layers.Dense(1024, activation=\"relu\")(x)\n","  predictions = keras.layers.Dense(29, activation=\"softmax\")(x)\n","\n","  # creating the final model \n","  model_final = Model(model.input, predictions)\n","  early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=5, verbose=1, mode='auto')\n","  model_final.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n","  history = model_final.fit(\n","        data_x, data_y,\n","        epochs = 64,\n","        validation_data = data_val,\n","        batch_size=BATCH_SIZE,\n","        shuffle=True,\n","        callbacks = [early])#,checkpoint])\n","  return history, model_final"],"metadata":{"id":"r3WnC9_hDHDx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Main"],"metadata":{"id":"lbYPwEHHwheJ"}},{"cell_type":"code","source":["DATA_AUGMENTATION = False\n","BATCH_SIZE = 128"],"metadata":{"id":"HVGys04r2kqR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = load_data(FILE_TRAIN) # Data is splitted\n","x_train = data[0]\n","labels_dict = load_labels()\n","y_vals = transform_labels(labels_dict, data)\n","y_train = y_vals[0]\n","if DATA_AUGMENTATION:\n","  x_train, y_train = data_augmentation(x_train, y_train, 0.2)\n","#data_train = DataGenerator(x_train, y_train, BATCH_SIZE)\n","#data_val = DataGenerator(data[2], y_vals[2], BATCH_SIZE)\n","print(y_train.shape, y_vals[2].shape)\n"],"metadata":{"id":"99R5Q20RNCSk","executionInfo":{"status":"ok","timestamp":1652523623933,"user_tz":-120,"elapsed":10,"user":{"displayName":"Ramon Mateo Navarro","userId":"07442703126175469251"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"99b8087d-c79e-484b-85be-0307ca523f95"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(20300, 29) (1450, 29)\n"]}]},{"cell_type":"markdown","source":["### Fine Tunning"],"metadata":{"id":"JurCYgVIOvcH"}},{"cell_type":"code","source":["#print(x_train[-10])\n","data_train = load_images(data[0])\n","\n","data_val = get_valSet(load_images(data[2]), y_vals[2])\n"],"metadata":{"id":"uNS9OlkZFRBB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_hist, model = train_model_fine(data_train, data_val, y_vals[0])\n","#model_hist, model = train_model_fine(data_train, data_val, y_train)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y4R8AJgzgUdi","executionInfo":{"status":"ok","timestamp":1652527728587,"user_tz":-120,"elapsed":4069867,"user":{"displayName":"Ramon Mateo Navarro","userId":"07442703126175469251"}},"outputId":"b825b6e9-40e2-495d-aa9e-692b96f82b75"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/64\n","159/159 [==============================] - ETA: 0s - loss: 4.1365 - accuracy: 0.0440"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n","  warnings.warn('This ImageDataGenerator specifies '\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r159/159 [==============================] - 209s 1s/step - loss: 4.1365 - accuracy: 0.0440 - val_loss: 3.1228 - val_accuracy: 0.0800\n","Epoch 2/64\n","159/159 [==============================] - 191s 1s/step - loss: 2.3674 - accuracy: 0.2673 - val_loss: 1.9043 - val_accuracy: 0.4034\n","Epoch 3/64\n","159/159 [==============================] - 193s 1s/step - loss: 1.7163 - accuracy: 0.4505 - val_loss: 1.6469 - val_accuracy: 0.4869\n","Epoch 4/64\n","159/159 [==============================] - 193s 1s/step - loss: 1.4706 - accuracy: 0.5283 - val_loss: 1.5359 - val_accuracy: 0.5028\n","Epoch 5/64\n","159/159 [==============================] - 193s 1s/step - loss: 1.3198 - accuracy: 0.5691 - val_loss: 1.3365 - val_accuracy: 0.5690\n","Epoch 6/64\n","159/159 [==============================] - 193s 1s/step - loss: 1.2202 - accuracy: 0.5993 - val_loss: 1.4233 - val_accuracy: 0.5462\n","Epoch 7/64\n","159/159 [==============================] - 193s 1s/step - loss: 1.1522 - accuracy: 0.6263 - val_loss: 1.3548 - val_accuracy: 0.5800\n","Epoch 8/64\n","159/159 [==============================] - 193s 1s/step - loss: 1.0606 - accuracy: 0.6497 - val_loss: 1.2758 - val_accuracy: 0.5966\n","Epoch 9/64\n","159/159 [==============================] - 193s 1s/step - loss: 1.0105 - accuracy: 0.6652 - val_loss: 1.2402 - val_accuracy: 0.6021\n","Epoch 10/64\n","159/159 [==============================] - 193s 1s/step - loss: 0.9246 - accuracy: 0.6933 - val_loss: 1.2904 - val_accuracy: 0.5917\n","Epoch 11/64\n","159/159 [==============================] - 193s 1s/step - loss: 0.8863 - accuracy: 0.7071 - val_loss: 1.3382 - val_accuracy: 0.5924\n","Epoch 12/64\n","159/159 [==============================] - 193s 1s/step - loss: 0.8381 - accuracy: 0.7196 - val_loss: 1.3088 - val_accuracy: 0.6214\n","Epoch 13/64\n","159/159 [==============================] - 193s 1s/step - loss: 0.8075 - accuracy: 0.7298 - val_loss: 1.3860 - val_accuracy: 0.6138\n","Epoch 14/64\n","159/159 [==============================] - 193s 1s/step - loss: 0.7698 - accuracy: 0.7431 - val_loss: 1.3805 - val_accuracy: 0.6159\n","Epoch 15/64\n","159/159 [==============================] - 193s 1s/step - loss: 0.7291 - accuracy: 0.7549 - val_loss: 1.4073 - val_accuracy: 0.5972\n","Epoch 16/64\n","159/159 [==============================] - 193s 1s/step - loss: 0.6968 - accuracy: 0.7667 - val_loss: 1.2943 - val_accuracy: 0.6324\n","Epoch 17/64\n","159/159 [==============================] - 193s 1s/step - loss: 0.6474 - accuracy: 0.7824 - val_loss: 1.4461 - val_accuracy: 0.6097\n","Epoch 18/64\n","159/159 [==============================] - 193s 1s/step - loss: 0.6290 - accuracy: 0.7858 - val_loss: 1.4408 - val_accuracy: 0.6069\n","Epoch 19/64\n","159/159 [==============================] - 193s 1s/step - loss: 0.6575 - accuracy: 0.7791 - val_loss: 1.4632 - val_accuracy: 0.6076\n","Epoch 20/64\n","159/159 [==============================] - 193s 1s/step - loss: 0.6223 - accuracy: 0.7912 - val_loss: 1.5405 - val_accuracy: 0.5883\n","Epoch 21/64\n","159/159 [==============================] - 193s 1s/step - loss: 0.6488 - accuracy: 0.7860 - val_loss: 1.6024 - val_accuracy: 0.6069\n","Epoch 21: early stopping\n"]}]},{"cell_type":"markdown","source":["## RESULTS"],"metadata":{"id":"G7qHVeWZDyD1"}},{"cell_type":"code","source":["def plot_training(history):\n","    import matplotlib\n","    matplotlib.use('Agg')\n","    import matplotlib.pyplot as plt\n","\n","    #Accuracy plot\n","    plt.plot(history.history['accuracy'])\n","    plt.plot(history.history['val_accuracy'])\n","    plt.title('model accuracy')\n","    plt.ylabel('accuracy')\n","    plt.xlabel('epoch')\n","    plt.legend(['train','val'], loc='upper left')\n","    plt.title('Training and validation accuracy')\n","    plt.savefig('fine_tuning_accuracy.pdf')\n","    plt.close()\n","    #Loss plot\n","    plt.plot(history.history['loss'])\n","    plt.plot(history.history['val_loss'])\n","    plt.title('model loss')\n","    plt.ylabel('loss')\n","    plt.xlabel('epoch')\n","    plt.legend(['train','val'], loc='upper left')\n","    plt.title('Training and validation loss')\n","    plt.savefig('fine_tuning_loss.pdf')\n","    plt.close()\n","plot_training(model_hist)"],"metadata":{"id":"n2zWE0P7D1ly"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Predicts"],"metadata":{"id":"PEmhDzlCZB4w"}},{"cell_type":"code","source":["x_test, y_test = data[1], y_vals[1]\n","correct = 0\n","for name_img, result in zip(x_test, y_test):\n","    img = cv2.imread('/content/data_256/' + name_img)\n","    img = cv2.resize(img, (256,256), interpolation = cv2.INTER_AREA)\n","    img = img[np.newaxis, :, :,:]\n","    prediction = model.predict(img)\n","    if np.argmax(prediction) == np.argmax(result):\n","      correct += 1\n","print(correct/len(x_test))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ThKUDyDoZJj4","executionInfo":{"status":"ok","timestamp":1652528595274,"user_tz":-120,"elapsed":866070,"user":{"displayName":"Ramon Mateo Navarro","userId":"07442703126175469251"}},"outputId":"6bf4c159-c41a-4459-b74a-6e0f3fa101b5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.4387175065465926\n"]}]},{"cell_type":"markdown","source":["## Cells for reset folders\n","\n","This cells are for reset folders and clear the images added using data Augmentation"],"metadata":{"id":"3cNdEE9_7xdA"}},{"cell_type":"code","source":["!rm -r data_256/*.jpg\n","!cp /content/drive/MyDrive/DL/L2/MAMe_data_256.zip .\n","!unzip MAMe_data_256.zip"],"metadata":{"id":"6kAp_hFl76Dd"},"execution_count":null,"outputs":[]}]}