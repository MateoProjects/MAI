function [net, tr,Y,E] = train_conf1(hiddenUnits, trainingRatio, validationRatio, test)

    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    %         1.1 LOGSIG LOGSIG MSE        %
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    
    % I is for select paramter 
    for i =1:3
        for j = 1:3
            net = feedforwardnet(hiddenUnits); % select hidden units
            for i =1:(length(net.layers)-1)
                net.layers{i}.transferFcn = 'logsig'; % you can use either logsig or tansig
            %net.layers{i}.transferFcn = 'tansig';
            end
            net.layers{end}.transferFcn = 'logsig';
            % Cost function: mese
            net.performFcn = 'mse';
            % Train function: Gradient descent with momentum
            net.trainFcn = 'traingdm'; 
            net.trainParam.lr = 0.5; 
            net.trainParam.mc = 0.8; 
            net.trainParam.epochs = 2000;
            %net.trainFcn = 'trainscg'; net.trainParam.lr = 0.1; net.trainParam.mc = 0.8; %net.trainParam.epochs= 1000;
            net.outputs{end}.processFcns = {}; 
            net.divideFcn = 'dividerand';% divideFCN allow to change the way the data is
            % divided into training, validation and test
            % data sets.
            net.divideParam.trainRatio = trainingRatio(i); % Ratio of data used as training set
            net.divideParam.valRatio = validationRatio(i); % Ratio of data used as validation set
            net.divideParam.testRatio = testRatio(i); % Ratio of data used as test set
            net.trainParam.max_fail = 6; % validation check parameter
            net.trainParam.min_grad = 1e-5; % minimum performance gradient
            [net,tr,Y,E] = train(net,P,T);
    
        end 
    end 

end

function [net, tr,Y,E] = train_conf2(hiddenUnits, trainingRatio, validationRatio)


    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    %   1.2 LOGSIG SOFTMAX CROSS ENTRHOPY  %
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    
    % I is for select paramter 
    
    
  
    for j = 1:3
        net2 = feedforwardnet(hiddenUnits(i)); % select hidden units
        for i =1:(length(net2.layers)-1)
            net2.layers{i}.transferFcn = 'logsig'; % you can use either logsig or tansig
        %net.layers{i}.transferFcn = 'tansig';
        end
        net2.layers{end}.transferFcn = 'softmax';
        % Cost function: crossentropy
        net2.performFcn = 'crossentropy';
        % Train function: Gradient descent with momentum
        net2.trainFcn = 'traingdm'; 
        net2.trainParam.lr = 0.5; 
        net2.trainParam.mc = 0.8; 
        net2.trainParam.epochs = 2000;
        net2.outputs{end}.processFcns = {}; 
        net2.divideFcn = 'dividerand';% divideFCN allow to change the way the data is
        % divided into training, validation and test
        % data sets.
        net2.divideParam.trainRatio = trainingRatio(i); % Ratio of data used as training set
        net2.divideParam.valRatio = validationRatio(i); % Ratio of data used as validation set
        net2.divideParam.testRatio = testRatio(i); % Ratio of data used as test set
        net2.trainParam.max_fail = 6; % validation check parameter
        net2.trainParam.min_grad = 1e-5; % minimum performance gradient
        [net,tr,Y,E] = train(net,P,T);
    end 

end 